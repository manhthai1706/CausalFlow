# CausalFlow: Detailed File-by-File Architecture

TÃ i liá»‡u nÃ y cung cáº¥p sÆ¡ Ä‘á»“ hoáº¡t Ä‘á»™ng chi tiáº¿t cho tá»«ng thÃ nh pháº§n trong mÃ£ nguá»“n cá»§a framework CausalFlow.

---

## ðŸ“‚ ThÆ° má»¥c `causalflow/core/` (Ná»n táº£ng thuáº­t toÃ¡n)

### 1. `mlp.py` - Ultimate Deep Learning Backbone
ÄÃ¢y lÃ  tá»‡p phá»©c táº¡p nháº¥t, chá»‹u trÃ¡ch nhiá»‡m trÃ­ch xuáº¥t thá»±c thá»ƒ vÃ  mÃ´ hÃ¬nh hÃ³a nhiá»…u.

```mermaid
graph TD
    IN[Input X] --> ATT[Attention Layer: Feature Selection]
    ATT --> GRN[Gated Residual Network: GRN]
    GRN --> RB[ResBlocks: Residual Learning]
    
    subgraph Multi-Head_Outputs
        RB --> VAE[VAE Head: mu, log_var for Mechanism Z]
        RB --> NSF[Monotonic Spline: Noise Transformation h_y]
        RB --> REG[Regressor: Probabilistic Output mu_y, var_y]
    end
    
    VAE --> Z[Softmax Z clusters]
    NSF --> HY[Y Transformation]
```

### 2. `gppom_hsic.py` - Core Engine & DAG Learning
Äiá»u phá»‘i viá»‡c há»c Ä‘á»“ thá»‹ nhÃ¢n quáº£ vÃ  káº¿t há»£p cÃ¡c hÃ m máº¥t mÃ¡t.

```mermaid
graph TD
    B[Batch Data] --> MLP[Call: mlp.py for Latents]
    MLP --> Z[Mechanism Z]
    
    subgraph DAG_Optimization
        W[W_dag Matrix] --> PEN[Acyclicity Penalty: h_W]
        W --> MASK[Structural Masking]
    end
    
    subgraph Prediction_Flow
        B & MASK --> GP[Random Fourier Features GP]
        GP --> PRED[Y Prediction]
    end
    
    PRED --> MSE[Loss: Regression]
    Z & B --> HSIC1[Loss: FastHSIC Clustering]
    PRED & B --> HSIC2[Loss: Adaptive HSIC PNL]
    
    MSE & PEN & HSIC1 & HSIC2 --> TOTAL[Total Loss & Backward]
```

### 3. `hsic.py` - Statistical Independence Testing
Triá»ƒn khai cÃ¡c phÃ©p thá»­ thá»‘ng kÃª Ä‘á»ƒ xÃ¡c nháº­n quan há»‡ nhÃ¢n quáº£.

```mermaid
graph LR
    subgraph hsic_gam
        A[Data X, Y] --> K[Compute Kernels K, L]
        K --> H[Trace Calculation]
        H --> GAM[Gamma Approximation]
        GAM --> P[p-value / Stat]
    end
    
    subgraph hsic_perm
        A1[Data] --> K1[Kernels]
        K1 --> SHUFFLE[Permutation/Shuffle]
        SHUFFLE --> DIST[Null Distribution]
    end
```

### 4. `kernels.py` - Differentiable Kernel Library
SÆ¡ Ä‘á»“ phÃ¢n cáº¥p cÃ¡c hÃ m nhÃ¢n cÃ³ thá»ƒ Ä‘áº¡o hÃ m.

```mermaid
graph TD
    K[Base Kernel] --> RBF[RBF / Gaussian]
    K --> MAT[Matern 3/2 & 5/2]
    K --> RQ[Rational Quadratic]
    K --> LIN[Linear / Poly]
    
    subgraph Optimization
        PARAM[log_alpha, log_gamma] --> GRAD[Learnable via SGD]
    end
```

---

## ðŸ“‚ ThÆ° má»¥c `causalflow/models/` (Giao diá»‡n & á»¨ng dá»¥ng)

### 5. `causalflow.py` - Sklearn-style Wrapper
Giao diá»‡n chÃ­nh cho ngÆ°á»i dÃ¹ng cuá»‘i.

```mermaid
graph TD
    START[CausalFlow Object] --> INIT[Init Dimensions & Device]
    INIT --> FIT[Method: fit]
    
    subgraph FIT_Logic
        FIT --> BIV[Check: Bivariate X, Y?]
        FIT --> MULTI[Check: Multivariate X?]
        BIV & MULTI --> TRAIN[Create: CausalFlowTrainer]
    end
    
    TRAIN --> RESULT[Update History & Weights]
    RESULT --> DAG[Method: get_dag_matrix]
```

### 6. `trainer.py` - Training Orchestrator
Quáº£n lÃ½ vÃ²ng láº·p huáº¥n luyá»‡n vÃ  lá»‹ch trÃ¬nh (scheduling).

```mermaid
graph TD
    LOOP[For Epoch in Epochs] --> TEMP[Adjust Temperature: Gumbel-Softmax]
    TEMP --> BATCH[For Batch in DataLoader]
    
    subgraph Batch_Processing
        BATCH --> ZERO[optimizer.zero_grad]
        ZERO --> FORWARD[model.forward]
        FORWARD --> BACK[loss.backward]
        BACK --> STEP[optimizer.step]
    end
    
    STEP --> LOG[Logging: Loss & HSIC Trend]
```

### 7. `analysis.py` - Causal Direction Discovery
LÃ´-gic phÃ¢n tÃ­ch nhÃ¢n quáº£ nÃ¢ng cao (SOTA 70.6%).

```mermaid
graph TD
    DATA[Raw Data Pair] --> PRE[Standardize / Quantile Transform]
    PRE --> CLEAN[Isolation Forest: Remove Outliers]
    
    subgraph Hypothesis_Testing
        CLEAN --> H1[Test Hypothesis: X -> Y]
        H1 --> LOCK1[Lock W_dag: Force Direction]
        LOCK1 --> SCORE1[Compute HSIC Stability Score 1]
        
        CLEAN --> H2[Test Hypothesis: Y -> X]
        H2 --> LOCK2[Lock W_dag: Force Direction]
        LOCK2 --> SCORE2[Compute HSIC Stability Score 2]
    end
    
    SCORE1 & SCORE2 --> COMP[Compare Scores]
    COMP --> DECIDE[Final Decision: Min Score Wins]
```
